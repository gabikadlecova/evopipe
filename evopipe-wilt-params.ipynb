{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "import evopipe\n",
    "import steps\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'wilt-train.csv'\n",
    "\n",
    "data = pd.read_csv(filename, sep=',')\n",
    "train_X = data[data.columns[1:]]\n",
    "train_Y = data[data.columns[0]]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "ix = train_Y.index\n",
    "train_Y = pd.Series(le.fit_transform(train_Y), index=ix)\n",
    "\n",
    "\n",
    "test_filename = 'wilt-test.csv'\n",
    "\n",
    "data = pd.read_csv(test_filename, sep=',')\n",
    "test_X = data[data.columns[1:]]\n",
    "test_Y = data[data.columns[0]]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "ix = test_Y.index\n",
    "test_Y = pd.Series(le.fit_transform(test_Y), index=ix)\n",
    "\n",
    "params = steps.get_params(len(train_X.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format:\n",
      "------------\n",
      "Classifier\n",
      "score\n",
      "cross-validation score\n",
      "GridSearch score\n",
      "------------\n",
      "\n",
      "SVC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3cb680609c6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mclassif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mclassif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Format:\")\n",
    "print(\"------------\")\n",
    "print(\"Classifier\")\n",
    "print(\"score\")\n",
    "print(\"cross-validation score\")\n",
    "print(\"GridSearch score\")\n",
    "print(\"------------\")\n",
    "print()\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for name, cls in steps.clfs.items():\n",
    "        classif = cls()\n",
    "        print(classif.__class__.__name__)\n",
    "        classif.fit(train_X, train_Y)\n",
    "        print(classif.score(test_X, test_Y))\n",
    "        print(model_selection.cross_val_score(classif, test_X, test_Y).mean())\n",
    "        \n",
    "        pipe_params = params[name]\n",
    "        gs = model_selection.GridSearchCV(classif, pipe_params, n_jobs=-1, verbose=5)\n",
    "        gs.fit(train_X, train_Y)\n",
    "        \n",
    "        print(gs.best_params_)\n",
    "        print(gs.score(test_X, test_Y))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolution starting...\n",
      "\n",
      "Gen 6:\n",
      "\n",
      "Hall of fame:\n",
      "[('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('kBest', OrderedDict([('k', 5)])), ('gaussianNB', OrderedDict())]\n",
      "[('gaussianNB', OrderedDict())]\n",
      "[('kBest', OrderedDict([('k', 5)])), ('LDA', OrderedDict([('shrinkage', 0.5), ('solver', 'eigen')]))]\n",
      "[('LDA', OrderedDict([('shrinkage', 0.5), ('solver', 'eigen')]))]\n",
      "\n",
      "Gen 11:\n",
      "\n",
      "Hall of fame:\n",
      "[('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('gaussianNB', OrderedDict())]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', True)])), ('PAC', OrderedDict([('C', 10), ('loss', 'squared_hinge')]))]\n",
      "[('kBest', OrderedDict([('k', 5)])), ('gaussianNB', OrderedDict())]\n",
      "[('gaussianNB', OrderedDict())]\n",
      "\n",
      "Gen 16:\n",
      "\n",
      "Hall of fame:\n",
      "[('kBest', OrderedDict([('k', 5)])), ('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('gaussianNB', OrderedDict())]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('MLP', OrderedDict([('activation', 'logistic'), ('alpha', 0.001), ('hidden_layer_sizes', (100,)), ('learning_rate', 'adaptive'), ('learning_rate_init', 0.01), ('max_iter', 200), ('momentum', 0.9), ('power_t', 0.5), ('solver', 'sgd'), ('tol', 0.001)]))]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', True)])), ('PAC', OrderedDict([('C', 10), ('loss', 'squared_hinge')]))]\n",
      "\n",
      "Gen 21:\n",
      "\n",
      "Hall of fame:\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', True)])), ('MLP', OrderedDict([('activation', 'relu'), ('alpha', 0.0001), ('hidden_layer_sizes', (50,)), ('learning_rate', 'adaptive'), ('learning_rate_init', 0.01), ('max_iter', 10), ('momentum', 0.9), ('power_t', 1), ('solver', 'lbfgs'), ('tol', 0.001)]))]\n",
      "[('kBest', OrderedDict([('k', 5)])), ('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('gaussianNB', OrderedDict())]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('MLP', OrderedDict([('activation', 'logistic'), ('alpha', 0.001), ('hidden_layer_sizes', (100,)), ('learning_rate', 'adaptive'), ('learning_rate_init', 0.01), ('max_iter', 200), ('momentum', 0.9), ('power_t', 0.5), ('solver', 'sgd'), ('tol', 0.001)]))]\n",
      "\n",
      "Gen 26:\n",
      "\n",
      "Hall of fame:\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', True)])), ('MLP', OrderedDict([('activation', 'relu'), ('alpha', 0.0001), ('hidden_layer_sizes', (50,)), ('learning_rate', 'adaptive'), ('learning_rate_init', 0.01), ('max_iter', 10), ('momentum', 0.9), ('power_t', 1), ('solver', 'lbfgs'), ('tol', 0.001)]))]\n",
      "[('kBest', OrderedDict([('k', 5)])), ('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('gaussianNB', OrderedDict())]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('MLP', OrderedDict([('activation', 'logistic'), ('alpha', 0.001), ('hidden_layer_sizes', (100,)), ('learning_rate', 'adaptive'), ('learning_rate_init', 0.01), ('max_iter', 200), ('momentum', 0.9), ('power_t', 0.5), ('solver', 'sgd'), ('tol', 0.001)]))]\n",
      "\n",
      "Gen 31:\n",
      "\n",
      "Hall of fame:\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', True)])), ('MLP', OrderedDict([('activation', 'relu'), ('alpha', 0.0001), ('hidden_layer_sizes', (50,)), ('learning_rate', 'adaptive'), ('learning_rate_init', 0.01), ('max_iter', 10), ('momentum', 0.9), ('power_t', 1), ('solver', 'lbfgs'), ('tol', 0.001)]))]\n",
      "[('QDA', OrderedDict([('reg_param', 0.1), ('tol', 0.01)]))]\n",
      "[('kBest', OrderedDict([('k', 5)])), ('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('gaussianNB', OrderedDict())]\n",
      "\n",
      "Gen 36:\n",
      "\n",
      "Hall of fame:\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', True)])), ('MLP', OrderedDict([('activation', 'relu'), ('alpha', 0.0001), ('hidden_layer_sizes', (50,)), ('learning_rate', 'adaptive'), ('learning_rate_init', 0.01), ('max_iter', 10), ('momentum', 0.9), ('power_t', 1), ('solver', 'lbfgs'), ('tol', 0.001)]))]\n",
      "[('QDA', OrderedDict([('reg_param', 0.1), ('tol', 0.01)]))]\n",
      "[('kBest', OrderedDict([('k', 5)])), ('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('QDA', OrderedDict([('reg_param', 0.5), ('tol', 0.01)]))]\n",
      "[('PCA', OrderedDict([('n_components', 5), ('whiten', False)])), ('gaussianNB', OrderedDict())]\n"
     ]
    }
   ],
   "source": [
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score, weights='quadratic')\n",
    "clf = evopipe.EvoPipeClassifier(steps.preproc, steps.clfs, params, mutpb=0.5, swap_mutpb=0.5, param_mutpb=0.85,\n",
    "                                ind_mutpb=0.8, scorer=scorer)\n",
    "clf.fit(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "score = clf.score(test_X, test_Y)\n",
    "print(\"\\nBest pipeline test score: {}\\n\".format(score))\n",
    "\n",
    "best_pipes = clf.best_pipelines()\n",
    "\n",
    "for pipe, score in best_pipes:\n",
    "    pipe.fit(train_X, train_Y)\n",
    "    # res_Y = pipe.predict(test_X)\n",
    "    \n",
    "    # score = metrics.cohen_kappa_score(test_Y, res_Y, weights='quadratic')\n",
    "    \n",
    "    pipe_named_steps = []\n",
    "    for key, val in pipe.steps:\n",
    "        pipe_named_steps.append(key)       \n",
    "    print(\"Score: {}, Pipe: {}\".format(score, pipe_named_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.logbook)\n",
    "\n",
    "gen = clf.logbook.select(\"gen\")\n",
    "avgs, mins, maxs, vars = clf.logbook.chapters[\"fitness\"].select(\"avg\", \"min\", \"max\", \"var\")\n",
    "avgs_tt, mins_tt, maxs_tt, vars_tt = clf.logbook.chapters[\"train_test\"].select(\"avg\", \"min\", \"max\", \"var\")\n",
    "\n",
    "sns.set()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "line1 = ax1.plot(gen, maxs, label='Maximum Fitness')\n",
    "ax1.set_xlabel(\"Generation\")\n",
    "ax1.set_ylabel(\"Fitness\")\n",
    "\n",
    "line2 = ax1.plot(gen, avgs, label='Average Fitness')\n",
    "\n",
    "line3 = ax1.plot(gen, maxs_tt, label='Maximum Test score')\n",
    "line4 = ax1.plot(gen, avgs_tt, label='Average Test score')\n",
    "\n",
    "lines = line1 + line2 + line3 + line4\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
